{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b52e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass Classification\n",
    "\n",
    "# Dataset Preparation\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import load_img,img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "013422f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Path.glob at 0x000002368385F3C0>\n"
     ]
    }
   ],
   "source": [
    "p = Path(\"./new/train\")\n",
    "dirs = p.glob(\"*\")\n",
    "print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0068112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\"PNEUMONIA\":0,\"NORMAL\":1}\n",
    "image_data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "823c3696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for folder_dir in dirs:\n",
    "    #print(folder_dir)\n",
    "    label = str(folder_dir).split(\"\\\\\")[-1][:-1]\n",
    "    #print(label)  # folder label name\n",
    "\n",
    "    for img_path in folder_dir.glob(\"*.jpeg\"):\n",
    "        # Now we got directory/path of all jpg files in folders\n",
    "        img = load_img(img_path,target_size=(32,32))\n",
    "        img_array = img_to_array(img)\n",
    "        image_data.append(img_array)\n",
    "        labels.append(labels_dict[label])\n",
    "\n",
    "image_data = np.array(image_data,dtype='float32')/255.0  # here we converted data into numpy array with all values lie b/w [0,1]\n",
    "labels = np.array(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7575fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle the data\n",
    "# First combining labels and numpy array of rgb data\n",
    "import random\n",
    "# zip\n",
    "combined = list(zip(image_data,labels))\n",
    "random.shuffle(combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "923c96b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip\n",
    "image_data[:],labels[:] = zip(*combined)\n",
    "# Now we got shuffled data of images as well as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5427a4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data visulaization -> pass the rgb data of iamge here and it will plot a image in matplotlib for it\n",
    "def drawImg(img):\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "drawImg(image_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca715789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(624, 3072)\n",
      "2\n",
      "(390, 3072)\n"
     ]
    }
   ],
   "source": [
    "# SVM CLASSIFIER\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self,c=1.0):\n",
    "        self.c = c\n",
    "        self.w = 0\n",
    "        self.b = 0\n",
    "    \n",
    "    def hingeLoss(self,w,b,x,y):\n",
    "        loss = 0.0\n",
    "        loss += 0.5*np.dot(w,w.T)\n",
    "\n",
    "        m = x.shape[0]\n",
    "        for i in range(m):\n",
    "            ti = y[i]*(np.dot(w,x[i].T)+b)\n",
    "            loss += self.c * max(0,(1-ti))\n",
    "        return loss[0][0]\n",
    "\n",
    "    def fit(self,x,y,batch_size=100,learning_rate=0.00001,maxItr=200):\n",
    "        no_of_features = x.shape[1]\n",
    "        no_of_samples = x.shape[0]\n",
    "\n",
    "        n = learning_rate\n",
    "        c = self.c\n",
    "\n",
    "        # Init the model parameters\n",
    "        w = np.zeros((1,no_of_features))\n",
    "        bias = 0\n",
    "\n",
    "        # print(self.hingeLoss(w,bias,x,y))   # Initial Loss\n",
    "\n",
    "        # Training from here...\n",
    "        losses = []\n",
    "        for i in range(maxItr):\n",
    "            # Training loop\n",
    "            l = self.hingeLoss(w,bias,x,y)\n",
    "            losses.append(l)\n",
    "            ids = np.arange(no_of_samples)\n",
    "            np.random.shuffle(ids)\n",
    "\n",
    "            # Batch gradient descent\n",
    "            for batch_start in range(0,no_of_samples,batch_size):\n",
    "                gradw = 0\n",
    "                gradb = 0\n",
    "\n",
    "                # Iterate over all examples in mini batch\n",
    "                for j in range(batch_start,batch_start+batch_size):\n",
    "                    if j<no_of_samples:\n",
    "                        ii = ids[j]\n",
    "                        ti = y[ii]*(np.dot(w,x[ii].T)+bias) \n",
    "                        if(ti>=1):\n",
    "                            gradw += 0\n",
    "                            gradb += 0\n",
    "                        else:\n",
    "                            gradw += (-1)*c*y[ii]*x[ii]\n",
    "                            gradb += (-1)*c*y[ii]\n",
    "                    else:\n",
    "                        break\n",
    "                w = w - n*w - n*gradw\n",
    "                bias = bias - n*gradb\n",
    "        self.w = w\n",
    "        self.b = bias\n",
    "        return w,bias,losses\n",
    "\n",
    "# We need to convert data for One vs One classification\n",
    "\n",
    "m = image_data.shape[0]\n",
    "image_data = image_data.reshape(m,-1)\n",
    "print(image_data.shape)\n",
    "\n",
    "classes = len(np.unique(labels))\n",
    "print(classes)\n",
    "\n",
    "def classWiseData(x,y):\n",
    "    data = {}\n",
    "    for i in range(classes):\n",
    "        data[i] = []\n",
    "    for i in range(x.shape[0]): \n",
    "        data[y[i]].append(x[i])\n",
    "    for k in data.keys():\n",
    "        data[k] = np.array(data[k])\n",
    "\n",
    "    return data\n",
    "\n",
    "data = classWiseData(image_data,labels)\n",
    "print(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5842173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataPairForSVM(d1,d2):\n",
    "                #label (if one class which we are checking if it is then 1 otherwise -1)\n",
    "    # ----------x--------------    y\n",
    "    #  .......................    -1\n",
    "    #  .......................     1\n",
    "    #  .......................    -1\n",
    "    #  .......................     1\n",
    "\n",
    "    # l1-> -1 ; l2-> +1 \n",
    "\n",
    "    l1,l2 = d1.shape[0],d2.shape[0]\n",
    "    samples = l1+l2\n",
    "    features = d1.shape[1]\n",
    "\n",
    "    data_pair = np.zeros((samples,features))\n",
    "    data_labels = np.zeros((samples,))\n",
    "\n",
    "    data_pair[:l1,:] = d1\n",
    "    data_pair[l1:,:] = d2\n",
    "\n",
    "    data_labels[:l1] = -1\n",
    "    data_labels[l1:] = +1\n",
    "\n",
    "    return data_pair,data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0fc642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training NC2 SVM'S PART!\n",
    "mySVM = SVM()\n",
    "def trainSVM(x,y):\n",
    "    svm_classifiers = {}\n",
    "    for i in range(classes):\n",
    "        svm_classifiers[i] = {}\n",
    "        for j in range(i+1,classes):\n",
    "            xpair,ypair = getDataPairForSVM(data[i],data[j])\n",
    "            wts,b,loss = mySVM.fit(xpair,ypair)\n",
    "            svm_classifiers[i][j] = (wts,b)\n",
    "    return svm_classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6257d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[-0.00887935, -0.00887935, -0.00887935, ...,  0.00176585,\n",
      "         0.00176585,  0.00176585]]), -0.01073999999999999)\n"
     ]
    }
   ],
   "source": [
    "# Here np.array(wts) is 3072 weights \n",
    "# svm_classifiers = {0:{1: (np.array(wts),bias),2: (np.array(wts),bias),3: (np.array(wts),bias)},1:{2: (np.array(wts),bias),3: (np.array(wts),bias)},2:{3: (np.array(wts),bias)}}\n",
    "svm_classifiers = trainSVM(image_data,labels)\n",
    "# Parameters for first two things\n",
    "print(svm_classifiers[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e4e8179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# PREDICTION\n",
    "\n",
    "def binaryPredict(x,w,b):\n",
    "    z = np.dot(x,w.T) + b\n",
    "    if(z>=0):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def predict(x):\n",
    "    count = np.zeros((classes,))\n",
    "    for i in range(classes):\n",
    "        for j in range(i+1,classes):\n",
    "            w,b = svm_classifiers[i][j]\n",
    "\n",
    "            # take a majority prediction\n",
    "            z = binaryPredict(x,w,b)\n",
    "\n",
    "            if(z==1):\n",
    "                count[j] += 1\n",
    "            else:\n",
    "                count[i] += 1\n",
    "\n",
    "    return max(count)\n",
    "\n",
    "print(labels[0])\n",
    "for item in image_data:\n",
    "    print(predict(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9ff51f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.5\n"
     ]
    }
   ],
   "source": [
    "def accuracy(x,y):\n",
    "    count = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        prediction = predict(x[i])\n",
    "        if(prediction==y[i]):\n",
    "            count+=1\n",
    "    return count/x.shape[0]\n",
    "\n",
    "print(accuracy(image_data,labels)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e9f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
